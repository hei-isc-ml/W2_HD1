{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676303fdc1c0a71f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Titanic - Machine Learning from Disaster (Skeleton)\n",
    "\n",
    "In this laboratory, you will implement a full machine learning pipeline, from preprocessing to model evaluation. \n",
    "The dataset we use is a famous one: [the Titanic dataset](https://www.kaggle.com/competitions/titanic/data) (yes, the big boat that sank...).\n",
    "\n",
    "The idea is simple: use ML to predict which passengers survived the Titanic shipwreck. The dataset is quite simple to understand but presents some real-world challenges (e.g., missing values). The explanation of the dataset is available at the link above.\n",
    "\n",
    "## Goals\n",
    "The goal of this lab is to guide you towards a higher level of autonomy when dealing with ML problems, in particular, classification problems (and in the later part, you will deal with a regression problem). \n",
    "This document provides just the skeleton of your program, reminding you of the main steps to be accomplished.\n",
    "At the end of this lab, you will be able to:\n",
    "- Work on a jupyter notebook for a ML problem.\n",
    "- Develop a full Machine Learning pipeline starting from a skeleton.\n",
    "- Perform data exploration and data preparation\n",
    "- Train, tune and **properly** evaluate different ML models (decision tree, random forest, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342301b41fc5526",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 Data exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d59d0",
   "metadata": {},
   "source": [
    "Check the intructions on the readme.md file on the assignment *W2_HD1 - Data exploration*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641806f0211cf39b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.1 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f96f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The library jupyter_black is used to format the code in the Jupyter Notebook in a format called \"Black\"\n",
    "# By using it, you agree to cede control over minutiae of hand-formatting.\n",
    "# You will save time and mental energy for more important matters.\n",
    "# You can make Jupyter auto-format every cell upon execution simply by adding the following lines at the top of the notebook\n",
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7be0d2d430b941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T07:20:10.110331Z",
     "start_time": "2024-09-04T07:20:10.104783Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbed7d45822a6c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T07:20:10.544422Z",
     "start_time": "2024-09-04T07:20:10.529579Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data (this may change depending on the location of the data: download the data from https://www.kaggle.com/competitions/titanic/data)\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0d61f0634c0c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1.2 Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151ddb1",
   "metadata": {},
   "source": [
    "##### To Do\n",
    "\n",
    "1. **Explore the Dataset**:\n",
    "   - Utilize functions and methods available in pandas (e.g., `.head()`, `.info()`, `.describe()`) or general Python techniques.\n",
    "   - Each time you gain new insights from the data, add a Markdown section to explain your observations and **discuss** the results.\n",
    "   - Refer to the questions in the `readme.md` file to deepen your analysis and answer them at the end of this notebook.\n",
    "\n",
    "##### Suggestions\n",
    "\n",
    "- **Start with the Training Set**:\n",
    "  - Perform initial analysis on the training set. Repeat the same operations on the test set, but remember to treat the test set as unavailable during training.\n",
    "  \n",
    "- **Initial Data Examination**:\n",
    "  - Inspect the first few rows of the data. Identify the features and the target variable. Determine which features might be relevant for predicting survival and which might not.\n",
    "  \n",
    "- **Dataset Size**:\n",
    "  - Assess the size of the dataset. Is it large or small? (Hint: It might be too early to tell at this stage.)\n",
    "  \n",
    "- **Feature Types**:\n",
    "  - Determine whether the features are numerical, categorical, or a mix of both. Identify their data types (e.g., float, int, string).\n",
    "  \n",
    "- **Dataset Balance**:\n",
    "  - Check if the dataset is balanced. Why or why not?\n",
    "  \n",
    "- **Missing Values**:\n",
    "  - Identify any missing values in the features. Are there missing values in the target variable `y`?\n",
    "  \n",
    "- **Feature Correlation**:\n",
    "  - Examine the correlation between features. Identify which features are correlated with the target variable `y`. Discuss the implications of these correlations. Is it beneficial or detrimental? Display the correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba780ae6c80c005b",
   "metadata": {},
   "source": [
    "#### 1.2.1 Explore the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2cddbcd85d2a72",
   "metadata": {},
   "source": [
    "#### 1.2.2 Explore the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8055545080555",
   "metadata": {},
   "source": [
    "### Answers to the questions (Data Exploration)\n",
    "- **Why is it important to know the type (numerical vs. categorical) of a feature?**\n",
    "\n",
    "*ToDo*\n",
    "\n",
    "- **Why is it important to understand correlations? Is it good to have features highly correlated with each other? Is it good to have features highly correlated with the target?**\n",
    "\n",
    "*ToDo*\n",
    " \n",
    "- **List possible problems related to an unbalanced dataset.**\n",
    "\n",
    "*ToDo*\n",
    "\n",
    "- **List possible solutions for dealing with an unbalanced dataset.**\n",
    "\n",
    "*ToDo*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6566117",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7df9bc13b9c5b3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adaf764",
   "metadata": {},
   "source": [
    "Check the intructions on the readme.md file of the assignment *W2_HD2 - Data preparation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1d43ba982292e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 Split the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2a9452247b4bcfd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4342f0e36f4c4977",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.2 Fill missing values (if any)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d70ae",
   "metadata": {},
   "source": [
    "##### Suggestions:\n",
    "- take care of not losing the original loaded dataset, then drop useless features\n",
    "- check the missing values on the train set and in the test set. If you decide to *impute* some values, the same policy used in the training set should be used in the test set.\n",
    "- take time to understand the difference between the scikit learn methods:\n",
    "    - .fit()\n",
    "    - .transform()\n",
    "    - .fit_transform()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08054c",
   "metadata": {},
   "source": [
    "##### Warning:\n",
    "Pandas behaviour is not the same when you use these two instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef5fc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_df[\"Embarked\"]\n",
    "type(test)  # print the type of the object (in this case, a pandas series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bdb83a",
   "metadata": {},
   "source": [
    "Or: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93eff6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train_df[[\"Embarked\"]]\n",
    "type(test)  # print the type of the object (in this case, it is a DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f35fe",
   "metadata": {},
   "source": [
    "In the first case, it returns a Series, in the second case a Dataframe. [They are not the same thing](https://www.geeksforgeeks.org/dataframe-vs-series-in-pandas/). Most of the time, you need a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee746414968df9f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 Separate the features X, from the label y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a02536115878e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.4 Scale and encode the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f3c7bd2393df23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.4.1 Scale the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2b152b090812f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "NOTE: it is arguable whether we should scale the `Pclass`, `SibSp` and `Parch` columns. We will do it here, but you can try to remove them from the list of columns to scale and see whther improves (or not) the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7215d7ec2710a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2.4.2 Encode the categorical features (one hot encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3535fc43148e85",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.5 Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17bea232ccd55461",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode the labels (label encoder)\n",
    "# we do not need to do this, as the labels are already binary (survived: 0 = No, 1 = Yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039067c4",
   "metadata": {},
   "source": [
    "### Answers to the questions (Data preparation)\n",
    "- **Why and when is it important to rescale/standardize the features?**\n",
    "\n",
    "\n",
    "- **What is the difference between Min-Max Scaler, Standard Scaler, and Robust Scaler?**\n",
    "    - Understand the formulas used for the Min-Max Scaler, Standard Scaler.\n",
    "    - Explain the possible impact of outliers on rescaling.\n",
    "\n",
    "\n",
    "- **Should I \"fit\" my scaler**:\n",
    "    - On the training set only?\n",
    "    - On the test set only?\n",
    "    - On both datasets (conjointly or separately)?\n",
    "    (and why)\n",
    "\n",
    "\n",
    "- **Feature Encoding**:\n",
    "    - What does the `OneHotEncoder` do?\n",
    "    - How does it differ from the `LabelEncoder`? When should you use one instead of the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bca009",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888934ef0623968",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3 Training and evaluation\n",
    "Check the intructions on the readme.md file of the assignment *W2_HD3 - Classification with Decision Tree*\n",
    "\n",
    "Suggestion:\n",
    "- structure the code below in a way that we can easily try different classifiers and compare their performance. Later on, we will use Random Forest on the same data.\n",
    "- review the readme.md file for the tasks to perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fa15ae9ed256da",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries (we will use GridSearchCV to find the best hyperparameters for each classifier)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1c24bbadf9e7613",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87b1682d",
   "metadata": {},
   "source": [
    "**NOTE**: it is very important to print scores related to the training set **and** to the validation set. This allows verifying possible overfitting/underfitting conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce41ca410dcbcbf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 k-nn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7922cb30ba44e3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ce83daa3117660b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de217f7d2555b85e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "def93c00",
   "metadata": {},
   "source": [
    "### Answers to the questions (Classification with Decision Tree)\n",
    "- **What are the hyperparameters of a Decision Tree? What do they represent?**\n",
    "\n",
    "\n",
    "- **How can you use k-fold cross-validation to select the best hyperparameters?**\n",
    "\n",
    "\n",
    "- **What is the difference between grid search and random search? Advantages and disadvantages?**\n",
    "\n",
    "\n",
    "- **How can the learning curve help you understand if your model is overfitting or underfitting the data? What are possible solutions when using a decision tree?**\n",
    " **Hint**: which hyperparameter(s) should you change to increase/decrease the probability to get overfitting? \n",
    "\n",
    "\n",
    "- **What is a confusion matrix for a 2-class problem? How does it differ for a multiclass problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d550d80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde2fa44e85b0d7a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 Random Forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db806e77",
   "metadata": {},
   "source": [
    "Check the intructions on the readme.md file of the assignment *W2_HD4 - Classification with Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee391694282bf2a8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd07b5e0",
   "metadata": {},
   "source": [
    "### Answers to the questions (Classification with Decision Tree)\n",
    "\n",
    "- **Present a step-by-step approach to implementing a Random Forest (RF) from Decision Trees.**\n",
    "\n",
    "\n",
    "- **What are the hyperparameters of a Random Forest? What do they represent?**\n",
    "\n",
    "\n",
    "- **How can the learning curve help you understand if your model is overfitting or underfitting the data?**\n",
    "\n",
    "\n",
    "- **What are the values in the x axis of a learning curve?**\n",
    "\n",
    "\n",
    "- **What are possible solutions to overfit/underfit using Random Forest ?**\n",
    "\n",
    "\n",
    "- **Talking about model evaluation, why is considering only \"accuracy\" not enough? Can you provide an example?**\n",
    "\n",
    "\n",
    "#### Random Forest (RF) vs. Decision Tree (DT)\n",
    "   - **Which approach is better for explainability and why?**\n",
    "\n",
    "\n",
    "   - **Do these approaches require feature rescaling? Why or why not?**\n",
    "\n",
    "\n",
    "   - **How should feature encoding be handled in each approach, and why?**\n",
    "\n",
    "   - **Which of these models provided a better classificatoin? Why? Is the difference statistically significant? How could you prove it?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66180fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9218c8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook you implemeneted a full ML pipeline: from data exploration, to the evaluation of multiple ML models (k-nn, decision tree, and random forest).\n",
    "We encourage you to use this same pipeline to all your ML projects. Most of the time, the model that you use is not as important as how you processed the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d771e6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
